{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4zp0nX_pc-N",
    "tags": []
   },
   "source": [
    "<center> <font size = 24 color = 'steelblue'> <b>Machine Translation<br>\n",
    "<img src = \"https://drive.google.com/uc?export=view&id=1kDOK8t-HSazBsqscjf11ml0NFlhiQxRh\" width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id= 'f0'> \n",
    "<font size = 4>\n",
    "    \n",
    "**Table of Contents:**<br>\n",
    "[1. Introduction](#f1)<br>\n",
    "[2. Loading libraries](#f2)<br>\n",
    "[3. Loading embeddings](#f3)<br>\n",
    "[4. Translating English dictionary to French](#f4)<br> \n",
    "> [4.1 Working with embeddings](#f4.1)<br>\n",
    "> [4.2 Computing the gradient of loss in respect to transform matrix R](#f4.2)<br>\n",
    "\n",
    "[5. Cosine Similarity](#f5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <a id = 'f1'>\n",
    "<font size = 10 color = 'midnightblue'> **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "\n",
    "- Machine translation involves the use of automated systems to translate text or speech from one language to another.\n",
    "- NLP plays a crucial role in understanding, interpreting, and generating human language in a way that considers context and meaning.\n",
    "- NLP techniques are employed to enhance the quality and accuracy of machine translation systems.\n",
    "- NLP helps in addressing linguistic nuances, context understanding, and idiosyncrasies specific to each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id = 'f2'>\n",
    "<font size = 10 color = 'midnightblue'> **Load the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RGOGrkD1yLk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pdb\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wj03n-wl1z3h",
    "outputId": "593ea9b7-eb57-495c-e931-5bbcb58ca7da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7c6UCC3zKD-",
    "outputId": "fc4d1ed1-81dc-4117-d2f5-125350f3b882",
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkHgR7CHzP20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = twitter_samples.strings('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhkSOPOn58OA",
    "tags": []
   },
   "source": [
    "##### <a id = 'f3'>\n",
    "<font size = 10 color = 'midnightblue'> **Load English and French embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6cBUUrM5cn_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\", \"rb\"))\n",
    "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J0WaJ7G17Zz0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# english to French dictionary :\n",
    "file = pd.read_csv('en-fr.train.txt', delimiter = ' ', header = None, index_col = [0]).squeeze(\"columns\")\n",
    "eng_to_french_dict_train  = file.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uDYY_b_V8ptE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv('en-fr.test.txt', delimiter = ' ', header = None, index_col = [0]).squeeze(\"columns\")\n",
    "eng_to_french_dict_test  = file.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-6G5c6s83CD",
    "tags": []
   },
   "source": [
    "##### <a id= 'f4'>\n",
    "<font size = 10 color = 'midnightblue'> **Translating English dictionary to French** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id = 'f4.1'>\n",
    "<font size = 6 color = 'pwdrblue'> <b>Working with embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-6G5c6s83CD"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "- Generate a matrix where where the columns are the English embeddings.\n",
    "- Generate a matrix where the columns correspond to the French embeddings.\n",
    "- Generate the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
    "\n",
    "> - The goal is often to find a transformation matrix that minimizes the difference between two matrices.\n",
    "> - The Frobenius norm is a way to measure the \"size\" or magnitude of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tW6J_l9R7rtA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the set of words of English\n",
    "\n",
    "eng_words = en_embeddings_subset.keys()\n",
    "frn_words = fr_embeddings_subset.keys()\n",
    "\n",
    "# get French words in the dictionary\n",
    "frnch_wrds_dict = eng_to_french_dict_test.values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzRmvJM3_VHO"
   },
   "source": [
    "<font size = 5 color = 'seagreen'> <b>Check whether embedding is present for both the English and French words present in translations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HZS3o98g-ueH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_emb, frn_emb = [],[]\n",
    "for eng, frnc in eng_to_french_dict_train.items():\n",
    "  if (eng in eng_words) and (frnc in frn_words):\n",
    "    # get the embeddings and store\n",
    "    eng_emb.append(en_embeddings_subset[eng])\n",
    "    frn_emb.append(fr_embeddings_subset[frnc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCprxnHGCxgW"
   },
   "source": [
    "<font size = 5 color = 'seagreen'> <b>Create English and French embedded matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzk-gEz2BY31",
    "outputId": "01c95382-f6c9-40ef-8ffb-86376b308cf2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.vstack(eng_emb)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jbaWHjMB7tw",
    "outputId": "85f84536-36f1-4f09-cabc-3120785f9258",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = np.vstack(frn_emb)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb_IWtZSC8B7"
   },
   "source": [
    "<font size = 5 color = 'seagreen'> <b>Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb_IWtZSC8B7"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "The loss function will be squared Frobenius norm of the difference between\n",
    "matrix and its approximation, divided by the number of training examples $m$.\n",
    "</div>\n",
    "\n",
    "<font size = 5>\n",
    "$$ L(X, Y, R)=\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left( a_{i j} \\right)^{2}$$\n",
    "\n",
    "\n",
    "<font size = 4>\n",
    "    \n",
    "<center> where $a_{i j}$ is value in $i$th row and $j$th column of the matrix $\\mathbf{XR}-\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kswNRk4mHrjs"
   },
   "source": [
    "##### <a id = 'f4.2'>\n",
    "<font size = 6 color = 'pwdrblue'> <b>Computing the gradient of loss in respect to transform matrix R\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "* Calculate the gradient of the loss with respect to transform matrix `R`.\n",
    "* The gradient is a matrix that encodes how much a small change in `R`\n",
    "affect the change in the loss function.\n",
    "* The gradient gives us the direction in which we should decrease `R`\n",
    "to minimize the loss.\n",
    "* $m$ is the number of training examples (number of rows in $X$).\n",
    "* The formula for the gradient of the loss function $ùêø(ùëã,ùëå,ùëÖ)$ is:\n",
    "\n",
    "$$\\frac{d}{dR}ùêø(ùëã,ùëå,ùëÖ)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wO9dgh2lIrWs",
    "outputId": "0a59ecf0-0d61-47c3-9e16-2f1a83e37de4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(129)\n",
    "# R is a square matrix with length equal to the number of dimensions in th  word embedding\n",
    "R = np.random.rand(X.shape[1], X.shape[1])\n",
    "train_steps=400\n",
    "learning_rate=0.8\n",
    "for i in range(train_steps):\n",
    "  if i % 25 == 0:\n",
    "    diff = np.dot(X,R) - Y\n",
    "    sq_diff = diff ** 2\n",
    "    loss = np.sum(sq_diff)/X.shape[0]\n",
    "    print(f\"loss at iteration {i} is: {loss:.4f}\")\n",
    "\n",
    "  gradient = np.dot(X.transpose(),np.dot(X,R)-Y)*(2/X.shape[0])\n",
    "  R -= learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTIb-4ciHvSV"
   },
   "source": [
    "##### <a id = 'f5'>\n",
    "<font size = 10 color = 'midnightblue'> <b>Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTIb-4ciHvSV"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "Cosine similarity between vectors $u$ and $v$ calculated as the cosine of the angle between them.\n",
    "The formula is\n",
    "\n",
    "$$\\cos(u,v)=\\frac{u\\cdot v}{\\left\\|u\\right\\|\\left\\|v\\right\\|}$$\n",
    "\n",
    "* $\\cos(u,v)$ = $1$ when $u$ and $v$ lie on the same line and have the same direction.\n",
    "* $\\cos(u,v)$ is $-1$ when they have exactly opposite directions.\n",
    "* $\\cos(u,v)$ is $0$ when the vectors are orthogonal (perpendicular) to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjRAVTovJihC",
    "outputId": "c6b85297-196b-45f7-b05c-937a280a1c09",
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_l = []\n",
    "for row in candidates:\n",
    "  # get the cosine similarity\n",
    "  cos_similarity = cosine_similarity(v,row)\n",
    "  # append the similarity to the list\n",
    "  similarity_l.append(cos_similarity)\n",
    "# sort the similarity list and get the indices of the sorted list\n",
    "sorted_ids = np.argsort(similarity_l)\n",
    "# get the indices of the k most similar candidate vectors\n",
    "_idx = sorted_ids[-k:]\n",
    "k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9WQMPV3zRKH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_l = []\n",
    "cosine_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfhdMm5KyxVW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The prediction is X times R\n",
    "    pred = np.dot(X,R)\n",
    "\n",
    "    # initialize the number correct to zero\n",
    "    num_correct = 0\n",
    "\n",
    "    # loop through each row in pred (each transformed embedding)\n",
    "    for i in range(len(pred)):\n",
    "        # get the index of the nearest neighbor of pred at row 'i'; also pass in the candidates in Y\n",
    "        pred_idx = nearest_neighbor(pred[i],Y)\n",
    "\n",
    "        # if the index of the nearest neighbor equals the row of i... \\\n",
    "        if pred_idx == i:\n",
    "            # increment the number correct by 1.\n",
    "            num_correct += 1\n",
    "\n",
    "    # accuracy is the number correct divided by the number of rows in 'pred' (also number of rows in X)\n",
    "    accuracy = num_correct / len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBVtVVCiYTJH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
